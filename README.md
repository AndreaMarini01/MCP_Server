# üß† MCP Server ‚Äì FastMCP + Ollama Integration

Questo progetto implementa un **MCP Server** basato su **FastMCP** per consentire a un modello LLM (come Llama 3.2 tramite Ollama) di interagire con risorse, strumenti e prompt personalizzati.  
L‚Äôarchitettura √® pensata per gestire pipeline di *Retrieval-Augmented Generation (RAG)* su dati strutturati e schemi FAISS.

---

## üöÄ Avvio rapido

### 1Ô∏è‚É£ Impostare i permessi di esecuzione
Rendi eseguibile lo script di inizializzazione di Ollama:
```bash
chmod +x init_ollama.sh

---

### 2Ô∏è‚É£ Inizializzare Ollama
Esegui lo script per avviare il servizio Ollama e scaricare il modello necessario (ad esempio `llama3.2:3b`):
```bash
./init_ollama.sh

---

### 3Ô∏è‚É£ Avviare il backend MCP
Lancia il container Docker del server FastMCP in modalit√† detached:
```bash
docker compose up -d backend
